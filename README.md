# DataEngineeringProject1
![image](https://user-images.githubusercontent.com/80721127/190935704-95800e00-871e-45ea-92af-f82672081be9.png)
#Business Use Case: 
	We have data coming to azure blob storage in json format and we need to create pipeline which will be able to convert this file into csv format and store in output folder. We will mount our databricks to output container and need to do data cleansing operations and convert into proper reporting format so that we will drive business metrics with the help of Tableau.
  
#Tools/Skills used
1. Azure Data Factory
2. Azure Data Bricks
3. pyspark and spark sql
4. Tableau
5. Azure Blob Storage

#Highlevel Steps 
1. Create blob storage in Azure.
2. Create data pipeline in Azure Data Factory.
3. Mount blob storage to databricks and perform cleaning using pyspark and spark sql.
4. Tableau for Visualization for business metrics.
